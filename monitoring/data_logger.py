"""
DataLogger ëª¨ë“ˆ
ì„¼ì„œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ì¡°íšŒí•˜ëŠ” ê¸°ëŠ¥ ì œê³µ

ì£¼ìš” ê¸°ëŠ¥:
- ì„¼ì„œ ë°ì´í„° CSV ì €ì¥
- ë‚ ì§œë³„ ìë™ íŒŒì¼ ë¶„ë¦¬
- ë°ì´í„° ì¡°íšŒ ë° í•„í„°ë§
- í†µê³„ ê³„ì‚° (í‰ê· , ìµœì†Œ, ìµœëŒ€)

ì‘ì„±ì: spinoza-lab
ë‚ ì§œ: 2026-02-12
"""

import csv
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import threading


class DataLogger:
    """
    ì„¼ì„œ ë°ì´í„° ë¡œê¹… í´ë˜ìŠ¤
    
    CSV í˜•ì‹ìœ¼ë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ì¡°íšŒ
    ë‚ ì§œë³„ë¡œ íŒŒì¼ì„ ìë™ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬
    """
    
    def __init__(self, log_dir: str = "/home/pi/smart_farm/logs"):
        """
        DataLogger ì´ˆê¸°í™”
        
        Args:
            log_dir: ë¡œê·¸ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í„°ë¦¬ ê²½ë¡œ
        """
        self.log_dir = log_dir
        self._lock = threading.Lock()
        
        # ë¡œê·¸ ë””ë ‰í„°ë¦¬ ìƒì„±
        self._ensure_log_directory()
        
        print(f"âœ… DataLogger ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ë¡œê·¸ ë””ë ‰í„°ë¦¬: {self.log_dir}")
    
    def _ensure_log_directory(self):
        """ë¡œê·¸ ë””ë ‰í„°ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)
            print(f"ğŸ“ ë¡œê·¸ ë””ë ‰í„°ë¦¬ ìƒì„±: {self.log_dir}")
    
    def _get_log_filename(self, date: Optional[datetime] = None) -> str:
        """
        ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë¡œê·¸ íŒŒì¼ëª… ë°˜í™˜
        
        Args:
            date: ë‚ ì§œ (Noneì´ë©´ ì˜¤ëŠ˜)
        
        Returns:
            ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        """
        if date is None:
            date = datetime.now()
        
        filename = f"sensors_{date.strftime('%Y-%m-%d')}.csv"
        return os.path.join(self.log_dir, filename)
    
    def _ensure_csv_header(self, filepath: str):
        """
        CSV íŒŒì¼ì— í—¤ë”ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
        
        Args:
            filepath: CSV íŒŒì¼ ê²½ë¡œ
        """
        # íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ í—¤ë” ì‘ì„±
        if not os.path.exists(filepath) or os.path.getsize(filepath) == 0:
            with open(filepath, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow([
                    'timestamp',
                    'tank1_level',
                    'tank2_level',
                    'ch0_voltage',
                    'ch1_voltage',
                    'ch2_voltage',
                    'ch3_voltage'
                ])
    
    def log_sensor_data(self, 
                       tank1_level: float,
                       tank2_level: float,
                       voltages: List[float],
                       timestamp: Optional[datetime] = None) -> bool:
        """
        ì„¼ì„œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ì— ê¸°ë¡
        
        Args:
            tank1_level: íƒ±í¬ 1 ìˆ˜ìœ„ (%)
            tank2_level: íƒ±í¬ 2 ìˆ˜ìœ„ (%)
            voltages: 4ì±„ë„ ì „ì•• ë¦¬ìŠ¤íŠ¸ [ch0, ch1, ch2, ch3]
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„ (Noneì´ë©´ í˜„ì¬ ì‹œê°„)
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            if timestamp is None:
                timestamp = datetime.now()
            
            # ë‚ ì§œë³„ íŒŒì¼ëª… ìƒì„±
            filepath = self._get_log_filename(timestamp)
            
            # ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë³´ì¥
            with self._lock:
                # í—¤ë” í™•ì¸
                self._ensure_csv_header(filepath)
                
                # ë°ì´í„° ê¸°ë¡
                with open(filepath, 'a', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow([
                        timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                        f"{tank1_level:.1f}",
                        f"{tank2_level:.1f}",
                        f"{voltages[0]:.3f}",
                        f"{voltages[1]:.3f}",
                        f"{voltages[2]:.3f}",
                        f"{voltages[3]:.3f}"
                    ])
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œê¹… ì‹¤íŒ¨: {e}")
            return False
    
    def get_data(self,
                 start_date: Optional[datetime] = None,
                 end_date: Optional[datetime] = None,
                 tank_filter: Optional[int] = None,
                 level_min: Optional[float] = None,
                 level_max: Optional[float] = None) -> List[Dict]:
        """
        ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ
        
        Args:
            start_date: ì¡°íšŒ ì‹œì‘ ë‚ ì§œ (Noneì´ë©´ ì˜¤ëŠ˜)
            end_date: ì¡°íšŒ ì¢…ë£Œ ë‚ ì§œ (Noneì´ë©´ start_dateì™€ ë™ì¼)
            tank_filter: íŠ¹ì • íƒ±í¬ë§Œ í•„í„°ë§ (1 ë˜ëŠ” 2)
            level_min: ìµœì†Œ ìˆ˜ìœ„ í•„í„°
            level_max: ìµœëŒ€ ìˆ˜ìœ„ í•„í„°
        
        Returns:
            ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [{timestamp, tank1_level, tank2_level, ...}, ...]
        """
        if start_date is None:
            start_date = datetime.now()
        
        if end_date is None:
            end_date = start_date
        
        # ë‚ ì§œ ë²”ìœ„ì˜ ëª¨ë“  íŒŒì¼ ì½ê¸°
        all_data = []
        current_date = start_date
        
        while current_date <= end_date:
            filepath = self._get_log_filename(current_date)
            
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r') as f:
                        reader = csv.DictReader(f)
                        for row in reader:
                            # í•„í„° ì ìš©
                            if self._apply_filters(row, tank_filter, level_min, level_max):
                                all_data.append(row)
                except Exception as e:
                    print(f"âš ï¸  íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({filepath}): {e}")
            
            current_date += timedelta(days=1)
        
        return all_data
    
    def _apply_filters(self,
                      row: Dict,
                      tank_filter: Optional[int],
                      level_min: Optional[float],
                      level_max: Optional[float]) -> bool:
        """
        ë°ì´í„° í–‰ì— í•„í„° ì¡°ê±´ ì ìš©
        
        Args:
            row: CSV í–‰ ë°ì´í„°
            tank_filter: íƒ±í¬ ë²ˆí˜¸ (1 ë˜ëŠ” 2)
            level_min: ìµœì†Œ ìˆ˜ìœ„
            level_max: ìµœëŒ€ ìˆ˜ìœ„
        
        Returns:
            í•„í„° í†µê³¼ ì—¬ë¶€
        """
        try:
            # íƒ±í¬ í•„í„°
            if tank_filter is not None:
                tank_key = f"tank{tank_filter}_level"
                level = float(row[tank_key])
                
                # ìˆ˜ìœ„ ë²”ìœ„ í•„í„°
                if level_min is not None and level < level_min:
                    return False
                if level_max is not None and level > level_max:
                    return False
            
            return True
            
        except (KeyError, ValueError):
            return False
    
    def get_statistics(self,
                      start_date: Optional[datetime] = None,
                      end_date: Optional[datetime] = None,
                      tank_num: int = 1) -> Dict:
        """
        ê¸°ê°„ë³„ í†µê³„ ê³„ì‚°
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            tank_num: íƒ±í¬ ë²ˆí˜¸ (1 ë˜ëŠ” 2)
        
        Returns:
            í†µê³„ ë”•ì…”ë„ˆë¦¬ {count, avg, min, max, first, last}
        """
        data = self.get_data(start_date, end_date)
        
        if not data:
            return {
                'count': 0,
                'avg': 0.0,
                'min': 0.0,
                'max': 0.0,
                'first': None,
                'last': None
            }
        
        tank_key = f"tank{tank_num}_level"
        levels = [float(row[tank_key]) for row in data]
        
        return {
            'count': len(levels),
            'avg': sum(levels) / len(levels),
            'min': min(levels),
            'max': max(levels),
            'first': levels[0],
            'last': levels[-1]
        }
    
    def get_latest_data(self, limit: int = 10) -> List[Dict]:
        """
        ìµœê·¼ ë°ì´í„° ì¡°íšŒ
        
        Args:
            limit: ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜
        
        Returns:
            ìµœê·¼ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        # ì˜¤ëŠ˜ê³¼ ì–´ì œ ë°ì´í„° ì¡°íšŒ
        today = datetime.now()
        yesterday = today - timedelta(days=1)
        
        data = self.get_data(start_date=yesterday, end_date=today)
        
        # ìµœì‹ ìˆœ ì •ë ¬ í›„ ì œí•œ
        return data[-limit:] if data else []
    
    def delete_old_logs(self, days_to_keep: int = 30) -> int:
        """
        ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ
        
        Args:
            days_to_keep: ë³´ê´€í•  ì¼ìˆ˜
        
        Returns:
            ì‚­ì œëœ íŒŒì¼ ê°œìˆ˜
        """
        deleted_count = 0
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        try:
            for filename in os.listdir(self.log_dir):
                if filename.startswith("sensors_") and filename.endswith(".csv"):
                    # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
                    date_str = filename.replace("sensors_", "").replace(".csv", "")
                    try:
                        file_date = datetime.strptime(date_str, "%Y-%m-%d")
                        
                        # ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ
                        if file_date < cutoff_date:
                            filepath = os.path.join(self.log_dir, filename)
                            os.remove(filepath)
                            deleted_count += 1
                            print(f"ğŸ—‘ï¸  ì‚­ì œë¨: {filename}")
                    
                    except ValueError:
                        continue
        
        except Exception as e:
            print(f"âŒ ë¡œê·¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        return deleted_count
    
    def get_log_files(self) -> List[Tuple[str, int]]:
        """
        ë¡œê·¸ íŒŒì¼ ëª©ë¡ ë° í¬ê¸° ì¡°íšŒ
        
        Returns:
            [(íŒŒì¼ëª…, í¬ê¸°(bytes)), ...] ë¦¬ìŠ¤íŠ¸
        """
        files = []
        
        try:
            for filename in sorted(os.listdir(self.log_dir)):
                if filename.startswith("sensors_") and filename.endswith(".csv"):
                    filepath = os.path.join(self.log_dir, filename)
                    size = os.path.getsize(filepath)
                    files.append((filename, size))
        
        except Exception as e:
            print(f"âŒ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return files


# ============================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================

def test_data_logger():
    """DataLogger í…ŒìŠ¤íŠ¸"""
    
    print("=" * 60)
    print("ğŸ§ª DataLogger í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print()
    
    # í…ŒìŠ¤íŠ¸ìš© ë¡œê·¸ ë””ë ‰í„°ë¦¬
    import tempfile
    test_dir = tempfile.mkdtemp()
    
    print("=" * 60)
    print("ğŸ“Š DataLogger ì´ˆê¸°í™”")
    print("=" * 60)
    logger = DataLogger(log_dir=test_dir)
    print()
    
    # [í…ŒìŠ¤íŠ¸ 1] ë°ì´í„° ë¡œê¹…
    print("[í…ŒìŠ¤íŠ¸ 1] ì„¼ì„œ ë°ì´í„° ë¡œê¹…")
    print("-" * 60)
    
    # ìƒ˜í”Œ ë°ì´í„° 10ê°œ ê¸°ë¡
    from datetime import datetime, timedelta
    base_time = datetime.now()
    
    for i in range(10):
        timestamp = base_time + timedelta(minutes=i)
        tank1 = 80.0 + i * 0.5
        tank2 = 75.0 + i * 0.3
        voltages = [2.0 + i * 0.01, 1.9 + i * 0.01, 0.6, 0.6]
        
        success = logger.log_sensor_data(
            tank1_level=tank1,
            tank2_level=tank2,
            voltages=voltages,
            timestamp=timestamp
        )
        
        if i == 0 or i == 9:
            print(f"âœ… ë°ì´í„° {i+1}/10 ê¸°ë¡: íƒ±í¬1={tank1:.1f}%, íƒ±í¬2={tank2:.1f}%")
    
    print(f"âœ… ì´ 10ê°œ ë°ì´í„° ê¸°ë¡ ì™„ë£Œ")
    print()
    
    # [í…ŒìŠ¤íŠ¸ 2] ë°ì´í„° ì¡°íšŒ
    print("[í…ŒìŠ¤íŠ¸ 2] ì „ì²´ ë°ì´í„° ì¡°íšŒ")
    print("-" * 60)
    
    all_data = logger.get_data()
    print(f"âœ… ì¡°íšŒëœ ë°ì´í„° ê°œìˆ˜: {len(all_data)}")
    
    if all_data:
        print(f"   ì²« ë²ˆì§¸: {all_data[0]['timestamp']} - íƒ±í¬1={all_data[0]['tank1_level']}%")
        print(f"   ë§ˆì§€ë§‰: {all_data[-1]['timestamp']} - íƒ±í¬1={all_data[-1]['tank1_level']}%")
    print()
    
    # [í…ŒìŠ¤íŠ¸ 3] í•„í„°ë§ ì¡°íšŒ
    print("[í…ŒìŠ¤íŠ¸ 3] í•„í„°ë§ ì¡°íšŒ (íƒ±í¬1 ìˆ˜ìœ„ >= 83%)")
    print("-" * 60)
    
    filtered_data = logger.get_data(tank_filter=1, level_min=83.0)
    print(f"âœ… ì¡°íšŒëœ ë°ì´í„° ê°œìˆ˜: {len(filtered_data)}")
    
    for row in filtered_data[:3]:
        print(f"   {row['timestamp']}: íƒ±í¬1={row['tank1_level']}%")
    print()
    
    # [í…ŒìŠ¤íŠ¸ 4] í†µê³„ ê³„ì‚°
    print("[í…ŒìŠ¤íŠ¸ 4] í†µê³„ ê³„ì‚° (íƒ±í¬1)")
    print("-" * 60)
    
    stats = logger.get_statistics(tank_num=1)
    print(f"âœ… ë°ì´í„° ê°œìˆ˜: {stats['count']}")
    print(f"   í‰ê· : {stats['avg']:.1f}%")
    print(f"   ìµœì†Œ: {stats['min']:.1f}%")
    print(f"   ìµœëŒ€: {stats['max']:.1f}%")
    print(f"   ì²« ê°’: {stats['first']:.1f}%")
    print(f"   ë§ˆì§€ë§‰ ê°’: {stats['last']:.1f}%")
    print()
    
    # [í…ŒìŠ¤íŠ¸ 5] ìµœê·¼ ë°ì´í„° ì¡°íšŒ
    print("[í…ŒìŠ¤íŠ¸ 5] ìµœê·¼ 5ê°œ ë°ì´í„°")
    print("-" * 60)
    
    latest = logger.get_latest_data(limit=5)
    print(f"âœ… ì¡°íšŒëœ ë°ì´í„°: {len(latest)}ê°œ")
    
    for row in latest:
        print(f"   {row['timestamp']}: íƒ±í¬1={row['tank1_level']}%, íƒ±í¬2={row['tank2_level']}%")
    print()
    
    # [í…ŒìŠ¤íŠ¸ 6] ë¡œê·¸ íŒŒì¼ ëª©ë¡
    print("[í…ŒìŠ¤íŠ¸ 6] ë¡œê·¸ íŒŒì¼ ëª©ë¡")
    print("-" * 60)
    
    files = logger.get_log_files()
    print(f"âœ… ë¡œê·¸ íŒŒì¼ ê°œìˆ˜: {len(files)}")
    
    for filename, size in files:
        print(f"   {filename}: {size} bytes")
    print()
    
    # í…ŒìŠ¤íŠ¸ ë””ë ‰í„°ë¦¬ ì •ë¦¬
    import shutil
    shutil.rmtree(test_dir)
    
    print("=" * 60)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    test_data_logger()
